"""
ë³´ì¡´ë ¥ ì‹œí—˜ OCR ë°±ì—”ë“œ ë¡œì§
Streamlitì—ì„œ ì§ì ‘ importí•˜ì—¬ ì‚¬ìš©
"""

import io
import re
import fitz
import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from openpyxl import Workbook
import os
import logging
import math
from typing import List, Dict, Tuple, Optional



# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ğŸ†• DRM ì²˜ë¦¬ ì¶”ê°€
try:
    from drm_utils import process_pdf_with_drm
    DRM_AVAILABLE = True
    logger.info("âœ… DRM ì²˜ë¦¬ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    DRM_AVAILABLE = False
    logger.warning("âš ï¸ drm_utils.py ì—†ìŒ - DRM ì²˜ë¦¬ ë¹„í™œì„±í™”")

from dotenv import load_dotenv
load_dotenv()
# ì„¤ì •
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
UPSTAGE_URL = "https://api.upstage.ai/v1/document-ai/document-parse"
STRAINS = ['E.coli', 'P.aeruginosa', 'S.aureus', 'C.albicans', 'A.brasiliensis']


class PDFProcessor:
    """PDF ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    # ğŸ†• DRM ì²˜ë¦¬ ì¶”ê°€
    @staticmethod
    def process_drm_if_needed(pdf_bytes: bytes) -> Tuple[bool, bytes, str]:
        """
        DRM ìë™ íŒë³„ ë° í•´ì œ
        
        Args:
            pdf_bytes: PDF ë°”ì´íŠ¸ ë°ì´í„°
            
        Returns:
            Tuple[bool, bytes, str]: (ì„±ê³µì—¬ë¶€, ì²˜ë¦¬ëœPDFë°”ì´íŠ¸, ë©”ì‹œì§€)
        """
        if not DRM_AVAILABLE:
            logger.warning("DRM ëª¨ë“ˆ ì—†ìŒ - ì›ë³¸ ì‚¬ìš©")
            return True, pdf_bytes, "DRM ëª¨ë“ˆ ì—†ìŒ (ì›ë³¸ ì‚¬ìš©)"
        
        try:
            # BytesIOë¡œ ë³€í™˜
            pdf_io = io.BytesIO(pdf_bytes)
            
            # DRM ì²˜ë¦¬
            success, result = process_pdf_with_drm(pdf_io)
            
            if success:
                # BytesIO â†’ bytes
                if isinstance(result, io.BytesIO):
                    result.seek(0)
                    processed_bytes = result.read()
                    logger.info(f"âœ… DRM ì²˜ë¦¬ ì™„ë£Œ ({len(processed_bytes):,} bytes)")
                    return True, processed_bytes, "DRM ì²˜ë¦¬ ì™„ë£Œ"
                else:
                    logger.info("âœ… DRM ì—†ìŒ (ì›ë³¸ ì‚¬ìš©)")
                    return True, pdf_bytes, "DRM ì—†ìŒ"
            else:
                error_msg = f"DRM í•´ì œ ì‹¤íŒ¨: {result}"
                logger.error(error_msg)
                return False, pdf_bytes, error_msg
        
        except Exception as e:
            error_msg = f"DRM ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"
            logger.error(error_msg)
            return False, pdf_bytes, error_msg
    
    @staticmethod
    def extract_page_count(pdf_bytes: bytes) -> int:
        """PDF í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ"""
        try:
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
            return doc.page_count
        except Exception as e:
            logger.error(f"í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 0
    
    @staticmethod
    def render_page_image(pdf_bytes: bytes, page_index: int, zoom: float = 2.0) -> bytes:
        """PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë Œë”ë§"""
        try:
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
            page = doc.load_page(page_index)
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat, alpha=False)
            return pix.tobytes("png")
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë Œë”ë§ ì‹¤íŒ¨: {e}")
            return None


class FallbackManager:
    """í˜ì´ì§€ë³„ fallback ë°ì´í„° ê´€ë¦¬"""
    
    def __init__(self):
        self.fallback_pairs = []
        self.ecoli_count = 0
        self.current_test_number = None
        self.current_prescription_number = None
    
    def reset(self):
        """í˜ì´ì§€ ë„˜ì–´ê°ˆ ë•Œ ì´ˆê¸°í™”"""
        self.fallback_pairs = []
        self.ecoli_count = 0
        self.current_test_number = None
        self.current_prescription_number = None
        logger.info("ğŸ”„ Fallback ì´ˆê¸°í™”ë¨")
    
    def add_pairs(self, pairs: List[Tuple[str, str]]):
        """fallbackì— ìŒ ì¶”ê°€"""
        self.fallback_pairs.extend(pairs)
        logger.info(f"ğŸ“¦ Fallback ì €ì¥: {pairs} (ì „ì²´: {len(self.fallback_pairs)}ê°œ)")
    
    def get_fallback_data(self, current_test=None, current_prescription=None):
        """fallbackì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        original_test = current_test
        original_prescription = current_prescription
        
        # ë‘˜ ë‹¤ ë¹„ì–´ìˆê³  fallbackì´ ìˆëŠ” ê²½ìš°
        if not current_test and not current_prescription and self.fallback_pairs:
            fallback_pair = self.fallback_pairs.pop(0)  # FIFO
            current_test, current_prescription = fallback_pair
            logger.info(f"ğŸ”„ ì „ì²´ Fallback ì ìš©: {original_test}, {original_prescription} â†’ {current_test}, {current_prescription}")
        
        # ì‹œí—˜ë²ˆí˜¸ë§Œ ë¹„ì–´ìˆëŠ” ê²½ìš°
        elif not current_test and self.fallback_pairs:
            for i, (fallback_test, fallback_prescription) in enumerate(self.fallback_pairs):
                if fallback_test:
                    current_test = fallback_test
                    self.fallback_pairs.pop(i)
                    logger.info(f"ğŸ”„ ì‹œí—˜ë²ˆí˜¸ Fallback ì ìš©: {original_test} â†’ {current_test}")
                    break
        
        # ì²˜ë°©ë²ˆí˜¸ë§Œ ë¹„ì–´ìˆëŠ” ê²½ìš°
        elif not current_prescription and self.fallback_pairs:
            for i, (fallback_test, fallback_prescription) in enumerate(self.fallback_pairs):
                if fallback_prescription:
                    current_prescription = fallback_prescription
                    self.fallback_pairs.pop(i)
                    logger.info(f"ğŸ”„ ì²˜ë°©ë²ˆí˜¸ Fallback ì ìš©: {original_prescription} â†’ {current_prescription}")
                    break
        
        return current_test, current_prescription
    
    def increment_ecoli_count(self):
        """E.coli ì¹´ìš´í„° ì¦ê°€"""
        self.ecoli_count += 1
        return self.ecoli_count
    
    
class OCRProcessor:
    """OCR ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def request_ocr(image_bytes: bytes) -> Optional[dict]:
        """ì—…ìŠ¤í…Œì´ì§€ OCR API í˜¸ì¶œ"""
        try:
            headers = {"Authorization": f"Bearer {UPSTAGE_API_KEY}"}
            files = {"document": ("image.jpg", image_bytes, "image/jpeg")}
            data = {
                "model": "document-parse",
                "ocr": "force",
                "base64_encoding": "['table']"
            }
            
            response = requests.post(
                UPSTAGE_URL, 
                headers=headers, 
                files=files, 
                data=data, 
                timeout=120
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"OCR API ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"OCR ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None
    
    @staticmethod
    def parse_table_from_ocr(ocr_result: dict, fallback_manager: FallbackManager = None) -> Tuple[List[dict], dict]:
        """OCR ê²°ê³¼ì—ì„œ í…Œì´ë¸” íŒŒì‹± (fallback ì§€ì›)"""
        try:
            # fallback_managerê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            if fallback_manager is None:
                fallback_manager = FallbackManager()
            
            html_parts = []
            if 'elements' in ocr_result:
                for element in ocr_result.get("elements", []):
                    content = element.get("content", {})
                    html = content.get("html", "")
                    if html:
                        html_parts.append(html)
            
            if not html_parts:
                logger.warning("HTML íŒŒíŠ¸ ì—†ìŒ")
                return [], {}
            
            html_content = "<html><body>\n" + "\n".join(html_parts) + "\n</body></html>"
            soup = BeautifulSoup(html_content, 'html.parser')
            table = soup.find('table')
            
            if not table:
                logger.warning("í…Œì´ë¸” ì—†ìŒ")
                return [], {}
            
            rows = table.find_all('tr')
            if len(rows) < 3:
                logger.warning(f"í–‰ ë¶€ì¡± ({len(rows)}ê°œ)")
                return [], {}
            
            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
            date_info = DataCleaner.extract_date_info(rows)
            
            # ğŸ†• fallback_manager ì „ë‹¬
            table_data = DataCleaner.parse_table_rows(rows, fallback_manager)
            
            return table_data, date_info
            
        except Exception as e:
            logger.error(f"í…Œì´ë¸” íŒŒì‹± ì˜¤ë¥˜: {e}")
            return [], {}


class DataCleaner:
    """ë°ì´í„° ì •ì œ í´ë˜ìŠ¤"""
    
    # ğŸ†• í´ë˜ìŠ¤ ë³€ìˆ˜: ë§ˆì§€ë§‰ ë‚ ì§œ ì •ë³´ ì €ì¥
    last_date_info = []
    
    @staticmethod
    def extract_date_info(rows) -> dict:
        """
        ë‚ ì§œ ì •ë³´ ì¶”ì¶œ (ê°œì„  ë²„ì „ + ì´ì „ ë‚ ì§œ ì¬ì‚¬ìš©)
        
        ê°œì„  ì‚¬í•­:
        - ì—°ì†ëœ ë‚ ì§œ ë¬¸ìì—´ ì§€ì› ì¶”ê°€
        - ê¸°ì¡´ ë¡œì§ ìœ ì§€
        - ğŸ†• ë‚ ì§œ ì—†ìœ¼ë©´ ì´ì „ í˜ì´ì§€ ë‚ ì§œ ì¬ì‚¬ìš©
        """
        date_info = {}
        if len(rows) >= 2:
            header_cells = rows[1].find_all('td')
            if len(header_cells) >= 1:
                first_date_str = header_cells[0].text.strip()
                
                # ğŸ†• ì—°ì† ë‚ ì§œ íŒ¨í„´ ë¨¼ì € ì‹œë„
                consecutive_dates = DataCleaner.parse_consecutive_dates(first_date_str)
                if consecutive_dates and len(consecutive_dates) >= 4:
                    date_info = {
                        'date_0': consecutive_dates[0],
                        'date_7': consecutive_dates[1],
                        'date_14': consecutive_dates[2],
                        'date_28': consecutive_dates[3]
                    }
                    # ğŸ†• ì„±ê³µí•˜ë©´ í´ë˜ìŠ¤ ë³€ìˆ˜ì— ì €ì¥
                    DataCleaner.last_date_info = date_info.copy()
                    logger.info(f"ğŸ“… ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì„±ê³µ: {date_info}")
                    return date_info
                
                # ê¸°ì¡´ ë°©ì‹ (ë‹¨ì¼ ë‚ ì§œ íŒŒì‹±)
                first_date = DataCleaner.parse_date(first_date_str)
                
                if first_date:
                    date_info = {
                        'date_0': first_date.strftime("%m/%d"),
                        'date_7': (first_date + timedelta(days=7)).strftime("%m/%d"),
                        'date_14': (first_date + timedelta(days=14)).strftime("%m/%d"),
                        'date_28': (first_date + timedelta(days=28)).strftime("%m/%d")
                    }
                    # ğŸ†• ì„±ê³µí•˜ë©´ í´ë˜ìŠ¤ ë³€ìˆ˜ì— ì €ì¥
                    DataCleaner.last_date_info = date_info.copy()
                    logger.info(f"ğŸ“… ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì„±ê³µ: {date_info}")
                    return date_info
        
        # ğŸ†• ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì´ì „ ê°’ ì¬ì‚¬ìš©
        if DataCleaner.last_date_info:
            logger.info(f"ğŸ”„ ì´ì „ ë‚ ì§œ ì •ë³´ ì¬ì‚¬ìš©: {DataCleaner.last_date_info}")
            return DataCleaner.last_date_info.copy()
        
        logger.warning("âš ï¸ ë‚ ì§œ ì •ë³´ ì—†ìŒ")
        return {}
    
    @staticmethod
    def parse_table_rows(rows, fallback_manager: FallbackManager = None) -> List[dict]:
        """í…Œì´ë¸” í–‰ íŒŒì‹± (fallback ì§€ì›)"""
        table_data = []
        
        # fallback_managerê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        if fallback_manager is None:
            fallback_manager = FallbackManager()
        
        # ë™ì  ì‹œì‘ì  ì°¾ê¸°
        data_start_row = 2
        for i, row in enumerate(rows):
            cells = row.find_all('td')
            if cells and cells[0].get('rowspan') and len(cells[0].text.strip()) > 10:
                data_start_row = i
                logger.info(f"ğŸ” ë°ì´í„° ì‹œì‘ì  ê°ì§€: Row {i}")
                break
        
        # ë°ì´í„° í–‰ ì²˜ë¦¬
        for i, row in enumerate(rows[data_start_row:], start=data_start_row+1):
            cells = row.find_all('td')
            if len(cells) < 1:
                continue
            
            # Bulk Name í–‰ ê°ì§€
            has_bulk_name = cells[0].get('rowspan') and cells[0].text.strip()
            
            if has_bulk_name:
                # ==================== Bulk Name ìˆëŠ” í–‰ ====================
                bulk_name = cells[0].text.strip()
                
                # ğŸ†• ë‹¤ì¤‘ íŒ¨í„´ ê°ì§€
                test_numbers, prescription_numbers = DataCleaner.extract_multiple_numbers(bulk_name)
                
                if len(test_numbers) > 1 or len(prescription_numbers) > 1:
                    logger.info(f"ğŸ” ë‹¤ì¤‘ íŒ¨í„´ ê°ì§€ - Bulk Name: {bulk_name}")
                    logger.info(f"   ì‹œí—˜ë²ˆí˜¸ë“¤: {test_numbers}")
                    logger.info(f"   ì²˜ë°©ë²ˆí˜¸ë“¤: {prescription_numbers}")
                    
                    # ğŸ†• ìŒ ìƒì„±
                    pairs = DataCleaner.create_matched_pairs(test_numbers, prescription_numbers, bulk_name)
                    
                    if pairs:
                        # ì²« ë²ˆì§¸ ìŒ ì‚¬ìš©
                        fallback_manager.current_test_number, fallback_manager.current_prescription_number = pairs[0]
                        
                        # ë‚˜ë¨¸ì§€ fallbackì— ì €ì¥
                        if len(pairs) > 1:
                            fallback_manager.add_pairs(pairs[1:])
                    else:
                        fallback_manager.current_test_number = test_numbers[0] if test_numbers else None
                        fallback_manager.current_prescription_number = prescription_numbers[0] if prescription_numbers else None
                else:
                    # ë‹¨ì¼ íŒ¨í„´
                    fallback_manager.current_test_number = test_numbers[0] if test_numbers else None
                    fallback_manager.current_prescription_number = prescription_numbers[0] if prescription_numbers else None
                
                if len(cells) > 1:
                    strain = cells[1].text.strip()
                    cfu_indices = {'0ì¼': 3, '7ì¼': 4, '14ì¼': 5, '28ì¼': 6, 'íŒì •': 7, 'ìµœì¢…íŒì •': 8}
                else:
                    continue
            else:
                # ==================== Bulk Name ì—†ëŠ” í–‰ ====================
                strain = cells[0].text.strip()
                cfu_indices = {'0ì¼': 2, '7ì¼': 3, '14ì¼': 4, '28ì¼': 5, 'íŒì •': 6, 'ìµœì¢…íŒì •': 7}
                
                # ğŸ†• E.coli ê°ì§€ ì‹œ fallback ì ìš©
                if 'E.coli' in strain or 'Escherichia' in strain:
                    ecoli_count = fallback_manager.increment_ecoli_count()
                    logger.info(f"ğŸ” E.coli #{ecoli_count} ê°ì§€: {strain}")
                    
                    # ë‘ ë²ˆì§¸ E.colië¶€í„° fallback ì ìš©
                    if ecoli_count > 1 and fallback_manager.fallback_pairs:
                        new_test, new_prescription = fallback_manager.get_fallback_data(None, None)
                        fallback_manager.current_test_number = new_test
                        fallback_manager.current_prescription_number = new_prescription
                        logger.info(f"ğŸ”„ E.coli #{ecoli_count} Fallback ì ìš©: {new_test}, {new_prescription}")
            
            # ìœ íš¨í•œ ê· ì£¼ í™•ì¸
            valid_strains = STRAINS + ['Escherichia', 'Pseudomonas', 'Staphylococcus', 'Candida', 'Aspergillus']
            if not strain or not any(valid_strain in strain for valid_strain in valid_strains):
                continue
            
            strain_normalized = DataCleaner.normalize_strain_name(strain)
            
            # CFU ë°ì´í„° ì¶”ì¶œ
            row_data = {
                'test_number': fallback_manager.current_test_number or '',
                'prescription_number': fallback_manager.current_prescription_number or '',
                'strain': strain_normalized,
                'cfu_0day': DataCleaner.clean_cfu_value(
                    cells[cfu_indices['0ì¼']].text.strip() if len(cells) > cfu_indices['0ì¼'] else "", 
                    strain_normalized, '0ì¼'
                ),
                'cfu_7day': DataCleaner.clean_cfu_value(
                    cells[cfu_indices['7ì¼']].text.strip() if len(cells) > cfu_indices['7ì¼'] else "", 
                    strain_normalized, '7ì¼'
                ),
                'cfu_14day': DataCleaner.clean_cfu_value(
                    cells[cfu_indices['14ì¼']].text.strip() if len(cells) > cfu_indices['14ì¼'] else "", 
                    strain_normalized, '14ì¼'
                ),
                'cfu_28day': DataCleaner.clean_cfu_value(
                    cells[cfu_indices['28ì¼']].text.strip() if len(cells) > cfu_indices['28ì¼'] else "", 
                    strain_normalized, '28ì¼'
                ),
                'judgment': DataCleaner.get_judgment_value(cells, cfu_indices),
                'final_judgment': DataCleaner.get_final_judgment_value(cells, cfu_indices)
            }
            
            if any(v for k, v in row_data.items() if k.startswith('cfu_') and v.strip()):
                table_data.append(row_data)
        
        return table_data
    
    @staticmethod
    def extract_numbers(bulk_name: str) -> Tuple[Optional[str], Optional[str]]:
        """
        ì‹œí—˜ë²ˆí˜¸ì™€ ì²˜ë°©ë²ˆí˜¸ ì¶”ì¶œ (ê°œì„  ë²„ì „)
        
        ê°œì„  ì‚¬í•­:
        - A-L ë²”ìœ„ë¡œ í™•ì¥ (ê¸°ì¡´: A-Z)
        - I/1 OCR ì˜¤ë¥˜ ìë™ ë³´ì •
        - ë” ë§ì€ ì²˜ë°©ë²ˆí˜¸ íŒ¨í„´ ì§€ì›
        - ê³µë°± ì²˜ë¦¬ ê°•í™”
        """
        test_number = None
        prescription_number = None
        
        try:
            # ì „ì²˜ë¦¬
            bulk_name = bulk_name.upper()
            bulk_name = bulk_name.replace('!', 'I')  # OCR ì˜¤ë¥˜ ë³´ì •
            bulk_name = re.sub(r'-\s+', '-', bulk_name)  # '- ' â†’ '-'
            bulk_name = re.sub(r'\s+', ' ', bulk_name)   # ì—°ì† ê³µë°± ì œê±°
            
            # ======== ì²˜ë°©ë²ˆí˜¸ íŒ¨í„´ (í™•ì¥) ========
            prescription_patterns = [
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-[A-Z]{1,4}\d?\b',
                r'\b[A-Z]{3}\d{5}-[A-Z]{2,4}\b',
                r'\bM-[A-Z]{2,4}\d{4,5}-[A-Z]{1,4}\d?\b',
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]-[A-Z]{1,4}[A-Z]?\b',
                r'\b[A-Z]{3,6}\d{2,4}-[A-Z]{1,4}\b',
                r'\b[A-Z]{2,4}\d{3,6}-[A-Z]{1,5}\b',
                r'\b[A-Z]{2,5}\d{4}-[A-Z]{1,3}\d{0,2}\b',
                r'\b[A-Z]{1,3}\d{4,5}-[A-Z]{2,4}[A-Z]?\b',
                r'\b[A-Z]{2,4}\d{4}-[A-Z]\d[A-Z]{1,3}\b',
                r'\b[A-Z]{2,4}\d{3,4}[A-Z]?-[A-Z]{1,4}\d*\b',
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-[A-Z]{1,5}\d?\b',
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-\s*[A-Z]{1,5}\d?\b',
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-[A-Z]{1,5}\d[A-Z]+\b',
                r'\b[A-Z]{2,4}\d{3,5}-[A-Z]{1,4}\d{1,2}\b',  # ğŸ¯ AZLY1 íƒ€ì…
                r'\b[A-Z]{2,5}\d{3,5}-[A-Z]{2,5}[A-Z\d]*\b',  # ğŸ¯ VAZAA íƒ€ì…
            ]
            
            all_prescription_matches = []
            for pattern in prescription_patterns:
                matches = re.findall(pattern, bulk_name)
                all_prescription_matches.extend(matches)
            
            # ======== ì‹œí—˜ë²ˆí˜¸ íŒ¨í„´ (A-L í™•ì¥ + OCR ë³´ì •) ========
            all_test_matches = []
            
            # ì •ìƒ í˜•íƒœ (Iê°€ ì •í™•íˆ ì¸ì‹ëœ ê²½ìš°)
            correct_matches = re.findall(r'\b(\d{2}[A-L]\d{2}I\d{2,3})\b', bulk_name)
            all_test_matches.extend(correct_matches)
            
            # OCR ì˜¤ë¥˜ í˜•íƒœ (Ië¥¼ 1ë¡œ ì˜ëª» ì¸ì‹)
            ocr_error_patterns = [
                r'\b(\d{2}[A-L]\d{2}1\d{2,3})\b',   # Iê°€ 1ë¡œ
                r'\b(\d{2}[A-L]\d{5,6})\b',         # I ëˆ„ë½
            ]
            
            for pattern in ocr_error_patterns:
                matches = re.findall(pattern, bulk_name)
                for match in matches:
                    if len(match) == 7:  # 25A2012 â†’ 25A20I2
                        corrected = match[:5] + 'I' + match[6:]
                        all_test_matches.append(corrected)
                        logger.info(f"OCR I/1 ë³´ì •: '{match}' â†’ '{corrected}'")
                    elif len(match) == 8:  # 25A20102 â†’ 25A20I02
                        corrected = match[:5] + 'I' + match[6:]
                        all_test_matches.append(corrected)
                        logger.info(f"OCR I ì‚½ì… ë³´ì •: '{match}' â†’ '{corrected}'")
            
            # ê³µë°±ì´ ìˆëŠ” í˜•íƒœ (A-L í™•ì¥)
            raw_matches = re.findall(r'(\d{2})([A-L])(\d)\s+(\d)(\d{2,3})', bulk_name)
            for year_prefix, letter, d1, d2, last_digits in raw_matches:
                converted = f"{year_prefix}{letter}{d1}{d2}I{last_digits[:2]}"
                all_test_matches.append(converted)
            
            # ì¤‘ë³µ ì œê±°
            all_test_matches = list(dict.fromkeys(all_test_matches))
            all_prescription_matches = list(dict.fromkeys(all_prescription_matches))
            
            test_number = all_test_matches[0] if all_test_matches else None
            prescription_number = all_prescription_matches[0] if all_prescription_matches else None
            
            return test_number, prescription_number
            
        except Exception as e:
            logger.warning(f"ë²ˆí˜¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None, None
    
    
    @staticmethod
    def extract_multiple_numbers(bulk_name: str) -> Tuple[List[str], List[str]]:
        """
        Bulk Nameì—ì„œ ë‹¤ì¤‘ ì‹œí—˜ë²ˆí˜¸ì™€ ì²˜ë°©ë²ˆí˜¸ ì¶”ì¶œ
        
        Returns:
            (ì‹œí—˜ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸, ì²˜ë°©ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸)
        """
        try:
            # ì „ì²˜ë¦¬
            bulk_name = bulk_name.upper()
            bulk_name = bulk_name.replace('!', 'I')
            bulk_name = re.sub(r'-\s+', '-', bulk_name)
            bulk_name = re.sub(r'\s+', ' ', bulk_name)
            
            # ì²˜ë°©ë²ˆí˜¸ íŒ¨í„´ (15ê°œ)
            prescription_patterns = [
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-[A-Z]{1,4}\d?\b',
                r'\b[A-Z]{3}\d{5}-[A-Z]{2,4}\b',
                r'\bM-[A-Z]{2,4}\d{4,5}-[A-Z]{1,4}\d?\b',
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]-[A-Z]{1,4}[A-Z]?\b',
                r'\b[A-Z]{3,6}\d{2,4}-[A-Z]{1,4}\b',
                r'\b[A-Z]{2,4}\d{3,6}-[A-Z]{1,5}\b',
                r'\b[A-Z]{2,5}\d{4}-[A-Z]{1,3}\d{0,2}\b',
                r'\b[A-Z]{1,3}\d{4,5}-[A-Z]{2,4}[A-Z]?\b',
                r'\b[A-Z]{2,4}\d{4}-[A-Z]\d[A-Z]{1,3}\b',
                r'\b[A-Z]{2,4}\d{3,4}[A-Z]?-[A-Z]{1,4}\d*\b',
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-[A-Z]{1,5}\d?\b',
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-\s*[A-Z]{1,5}\d?\b',
                r'\b[A-Z]{2,4}\d{4,5}[A-Z]?-[A-Z]{1,5}\d[A-Z]+\b',
                r'\b[A-Z]{2,4}\d{3,5}-[A-Z]{1,4}\d{1,2}\b',
                r'\b[A-Z]{2,5}\d{3,5}-[A-Z]{2,5}[A-Z\d]*\b',
            ]
            
            all_prescription_matches = []
            for pattern in prescription_patterns:
                matches = re.findall(pattern, bulk_name)
                all_prescription_matches.extend(matches)
            
            # ì‹œí—˜ë²ˆí˜¸ íŒ¨í„´
            test_patterns = [
                r'\b(\d{2}[A-L]\d{2}I\d{2,3})\b',  # ì •ìƒ
                r'\b(\d{2}[A-L]\d{2}1\d{2,3})\b',  # Iâ†’1 ì˜¤ì¸
            ]
            
            all_test_matches = []
            for pattern in test_patterns:
                matches = re.findall(pattern, bulk_name)
                for match in matches:
                    if '1' in match[5:7]:
                        corrected = match[:5] + 'I' + match[6:]
                        all_test_matches.append(corrected)
                        logger.info(f"ğŸ”§ OCR I/1 ë³´ì •: '{match}' â†’ '{corrected}'")
                    else:
                        all_test_matches.append(match)
            
            # ì¤‘ë³µ ì œê±°
            all_test_matches = list(dict.fromkeys(all_test_matches))
            all_prescription_matches = list(dict.fromkeys(all_prescription_matches))
            
            return all_test_matches, all_prescription_matches
            
        except Exception as e:
            logger.error(f"ë‹¤ì¤‘ ë²ˆí˜¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return [], []

    @staticmethod
    def create_matched_pairs(test_numbers: List[str], prescription_numbers: List[str], bulk_name: str) -> List[Tuple[str, str]]:
        """
        ì‹œí—˜ë²ˆí˜¸ì™€ ì²˜ë°©ë²ˆí˜¸ ë§¤ì¹­ (ìœ„ì¹˜ ê¸°ë°˜)
        
        Returns:
            [(ì‹œí—˜ë²ˆí˜¸, ì²˜ë°©ë²ˆí˜¸), ...] ìŒ ë¦¬ìŠ¤íŠ¸
        """
        pairs = []
        
        try:
            # ìœ„ì¹˜ ê¸°ë°˜ ë§¤ì¹­
            test_positions = []
            for test_num in test_numbers:
                pos = bulk_name.find(test_num)
                if pos != -1:
                    test_positions.append((test_num, pos))
            
            prescription_positions = []
            for prescription_num in prescription_numbers:
                pos = bulk_name.find(prescription_num)
                if pos != -1:
                    prescription_positions.append((prescription_num, pos))
            
            # ìˆœì„œëŒ€ë¡œ ë§¤ì¹­
            for i, test_num in enumerate(test_numbers):
                if i < len(prescription_numbers):
                    pairs.append((test_num, prescription_numbers[i]))
                else:
                    pairs.append((test_num, None))
            
            # ì‰ì—¬ ì²˜ë°©ë²ˆí˜¸ ì²˜ë¦¬
            if len(prescription_numbers) > len(test_numbers):
                for i in range(len(test_numbers), len(prescription_numbers)):
                    pairs.append((None, prescription_numbers[i]))
            
            logger.info(f"ğŸ“ ë§¤ì¹­ ê²°ê³¼: {pairs}")
            return pairs
            
        except Exception as e:
            logger.error(f"ìŒ ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            return []
    
    @staticmethod
    def normalize_strain_name(strain: str) -> str:
        """ê· ì£¼ëª… ì •ê·œí™”"""
        strain_mapping = {
            'E.coli': 'E.coli', 'Escherichia coli': 'E.coli', 'E. coli': 'E.coli',
            'P.aeruginosa': 'P.aeruginosa', 'Pseudomonas aeruginosa': 'P.aeruginosa', 'P. aeruginosa': 'P.aeruginosa',
            'S.aureus': 'S.aureus', 'Staphylococcus aureus': 'S.aureus', 'S. aureus': 'S.aureus',
            'C.albicans': 'C.albicans', 'Candida albicans': 'C.albicans', 'C. albicans': 'C.albicans',
            'A.brasiliensis': 'A.brasiliensis', 'Aspergillus brasiliensis': 'A.brasiliensis', 'A. brasiliensis': 'A.brasiliensis'
        }
        
        for full_name, short_name in strain_mapping.items():
            if full_name.lower() == strain.lower():
                return short_name
        
        for full_name, short_name in strain_mapping.items():
            if full_name.lower() in strain.lower():
                return short_name
        
        return strain
    
    @staticmethod
    def clean_cfu_value(value: str, strain: str = None, day_column: str = None) -> str:
        """CFU ê°’ ì •ë¦¬ ë° ë³´ì •"""
        if not value:
            return ""
        
        original_value = value
        
        # OCR ì˜¤ë¥˜ ì œê±°
        value = re.sub(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯]+', '', value)
        value = value.replace('ã', '<').replace('C', '<').replace('O', '0')
        value = value.replace('Co', '0').replace('CIO', '<10').replace('C10', '<10')
        value = value.strip()
        
        # ì§€ìˆ˜ í˜•íƒœ ì²˜ë¦¬
        if re.search(r'[Ã—xX]', value):
            exp_match = re.match(r'([0-9.]+)\s*[Ã—xX]\s*10\s*\^?([0-9]+)', value)
            if exp_match:
                base = exp_match.group(1)
                exp = exp_match.group(2)
                return f"{base}Ã—10^{exp}"
        
        # <10 í˜•íƒœ ì²˜ë¦¬
        if '<' in value:
            if re.search(r'<\s*10\s*\^?\s*([0-9]+)', value):
                exp = re.search(r'<\s*10\s*\^?\s*([0-9]+)', value).group(1)
                return f"<10^{exp}"
            elif re.search(r'<\s*([0-9]+)', value):
                return f"<{re.search(r'<\s*([0-9]+)', value).group(1)}"
            return "<10"
        
        # â‰¤ í˜•íƒœ ì²˜ë¦¬
        if 'â‰¤' in value:
            if re.search(r'â‰¤\s*([0-9]+)', value):
                num = re.search(r'â‰¤\s*([0-9]+)', value).group(1)
                return f"â‰¤{num}"
        
        # ê· ì£¼ë³„ ë³´ì •
        target_strains = ['E.coli', 'P.aeruginosa', 'S.aureus', 'C.albicans']
        is_target_strain = strain and any(s in strain for s in target_strains)
        
        if day_column in ['7ì¼', '14ì¼', '28ì¼'] and is_target_strain:
            preserve_patterns = [r'^â‰¤\d+[Â°â°]?$']
            should_preserve = any(re.match(pattern, value, re.IGNORECASE) for pattern in preserve_patterns)
            if should_preserve:
                return value
            
            if len(original_value) >= 6:
                return value
            
            if day_column == '7ì¼':
                corrected_value = "<10^2"
            elif day_column in ['14ì¼', '28ì¼']:
                corrected_value = "<10"
            else:
                corrected_value = "<10"
            
            has_clear_power_signal = ('2' in original_value and 
                                    any(char in original_value for char in ['^', 'Â²', 'â°', 'Â¹', 'Â²', 'Â³']))
            
            if has_clear_power_signal and day_column != '28ì¼':
                corrected_value = "<10^2"
            
            return corrected_value
        
        return value
    
    @staticmethod
    def get_judgment_value(cells, cfu_indices: dict) -> str:
        """íŒì • ê°’ ì¶”ì¶œ"""
        try:
            if len(cells) > cfu_indices['íŒì •']:
                raw_value = cells[cfu_indices['íŒì •']].text.strip()
                if any(char in raw_value for char in ['X', 'Ã—', 'v', 'V']):
                    return 'ë¶€ì í•©'
                return 'ì í•©'
            return "ì í•©"
        except:
            return "ì í•©"
    
    @staticmethod
    def get_final_judgment_value(cells, cfu_indices: dict) -> str:
        """ìµœì¢…íŒì • ê°’ ì¶”ì¶œ"""
        try:
            if len(cells) > cfu_indices['ìµœì¢…íŒì •']:
                raw_value = cells[cfu_indices['ìµœì¢…íŒì •']].text.strip()
                if any(char in raw_value for char in ['X', 'Ã—', 'v', 'V']):
                    return 'ë¶€ì í•©'
                return 'ì í•©'
            return "ì í•©"
        except:
            return "ì í•©"
        
    @staticmethod
    def parse_consecutive_dates(date_text: str) -> List[str]:
        """
        ì—°ì†ëœ ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±
        
        ì˜ˆì‹œ: '01 15 01 22 01 29 02 12' â†’ ['01/15', '01/22', '01/29', '02/12']
        
        Args:
            date_text (str): ì—°ì†ëœ ë‚ ì§œ ë¬¸ìì—´
            
        Returns:
            List[str]: ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ (4ê°œ)
        """
        try:
            parts = date_text.split()
            
            if len(parts) >= 8 and all(part.isdigit() and len(part) == 2 for part in parts):
                dates = []
                for i in range(0, min(8, len(parts)), 2):
                    if i + 1 < len(parts):
                        month = parts[i]
                        day = parts[i + 1]
                        dates.append(f"{month}/{day}")
                
                if len(dates) >= 4:
                    return dates[:4]
            
            return []
            
        except Exception as e:
            logger.warning(f"ì—°ì† ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []
        
    @staticmethod
    def parse_date(date_str: str) -> Optional[datetime]:
        """ë‚ ì§œ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜"""
        try:
            date_formats = [
                '%m %d', '%m-%d', '%m/%d', '%m.%d',
                '%mì›”%dì¼', '%mì›” %dì¼',
                '%d/%m', '%d-%m', '%d %m'
            ]
            
            for date_format in date_formats:
                try:
                    return datetime.strptime(date_str, date_format)
                except ValueError:
                    continue
            
            if re.match(r'^\d+\s+\d+$', date_str):
                try:
                    return datetime.strptime(date_str, '%m %d')
                except ValueError:
                    pass
            
            return None
        except:
            return None
    
    @staticmethod
    def convert_to_log(cfu_value: str) -> str:
        """CFU â†’ Log ë³€í™˜"""
        if not cfu_value:
            return ""
        
        try:
            if '<' in cfu_value:
                if '10^' in cfu_value:
                    exp_match = re.search(r'<10\^(\d+)', cfu_value)
                    if exp_match:
                        return f"<{exp_match.group(1)}.0"
                elif 'â‰¤' in cfu_value:
                    num_match = re.search(r'â‰¤(\d+)', cfu_value)
                    if num_match:
                        return f"<{num_match.group(1)}.0"
                return "<1.0"
            
            exp_match = re.match(r'([0-9.]+)Ã—10\^(\d+)', cfu_value)
            if exp_match:
                base = float(exp_match.group(1))
                exp = int(exp_match.group(2))
                log_value = exp + math.log10(base)
                return round(log_value, 1)
            
            try:
                num = float(cfu_value)
                return round(math.log10(num), 1)
            except ValueError:
                pass
            
            return cfu_value
            
        except Exception as e:
            logger.warning(f"Log ë³€í™˜ ì‹¤íŒ¨: {cfu_value}, ì˜¤ë¥˜: {e}")
            return cfu_value
        

class ExcelIncrementalSaver:
    """
    Excel ì¦ë¶„ ì €ì¥ ê´€ë¦¬ í´ë˜ìŠ¤
    
    ê¸°ëŠ¥:
    - í˜ì´ì§€ ì²˜ë¦¬í•  ë•Œë§ˆë‹¤ ì¦‰ì‹œ Excel íŒŒì¼ì— ì €ì¥
    - í…œí”Œë¦¿ ê¸°ë°˜ ì‹œíŠ¸ ìƒì„± (copy_worksheet ì‚¬ìš©)
    - ì¤‘ë³µ ì‹œíŠ¸ëª… ìë™ ì²˜ë¦¬
    """
    
    # ğŸ†• ê¸°ë³¸ í…œí”Œë¦¿ íŒŒì¼ ê²½ë¡œ
    DEFAULT_TEMPLATE = "TestResult_OCR_v1.xlsx"
    
    def __init__(self, output_path="ë³´ì¡´ë ¥ì‹œí—˜_ìµœì¢….xlsx", template_file=None):
        """
        Args:
            output_path (str): ì €ì¥í•  Excel íŒŒì¼ ê²½ë¡œ
            template_file (str): í…œí”Œë¦¿ Excel íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.output_path = output_path
        
        # ğŸ†• template_fileì´ Noneì´ë©´ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
        if template_file is None:
            self.template_file = self.DEFAULT_TEMPLATE
        else:
            self.template_file = template_file
        
        # ğŸ†• í…œí”Œë¦¿ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(self.template_file):
            logger.warning(f"âš ï¸ í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.template_file}")
            logger.warning("ë¹ˆ Excel íŒŒì¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.")
            self.template_file = None
        else:
            logger.info(f"âœ… í…œí”Œë¦¿ íŒŒì¼ í™•ì¸: {self.template_file}")
        
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if not os.path.exists(self.output_path):
            self._initialize_excel()
    
    def _initialize_excel(self):
        """Excel íŒŒì¼ ì´ˆê¸°í™”"""
        try:
            if self.template_file and os.path.exists(self.template_file):
                # ğŸ†• í…œí”Œë¦¿ íŒŒì¼ ì „ì²´ ë³µì‚¬
                import shutil
                shutil.copy2(self.template_file, self.output_path)
                
                # ğŸ†• ì²« ë²ˆì§¸ ì‹œíŠ¸ë¥¼ TEMPLATE_BASEë¡œ ì´ë¦„ ë³€ê²½
                from openpyxl import load_workbook
                workbook = load_workbook(self.output_path)
                
                if len(workbook.sheetnames) > 0:
                    first_sheet = workbook[workbook.sheetnames[0]]
                    first_sheet.title = "TEMPLATE_BASE"
                    logger.info(f"âœ… í…œí”Œë¦¿ ì‹œíŠ¸ '{workbook.sheetnames[0]}' â†’ 'TEMPLATE_BASE'ë¡œ ë³€ê²½")
                
                workbook.save(self.output_path)
                workbook.close()
                
                logger.info(f"âœ… í…œí”Œë¦¿ ê¸°ë°˜ Excel ì´ˆê¸°í™” ì™„ë£Œ: {self.output_path}")
            else:
                # ë¹ˆ Excel ìƒì„±
                wb = Workbook()
                wb.remove(wb.active)
                wb.save(self.output_path)
                wb.close()
                
                logger.warning(f"âš ï¸ í…œí”Œë¦¿ ì—†ì´ ë¹ˆ Excel íŒŒì¼ ìƒì„±: {self.output_path}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ Excel ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def add_test_data(self, test_data, date_info=None):
        """
        í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ Excelì— ì¶”ê°€
        
        Args:
            test_data: DataFrame ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            date_info: ë‚ ì§œ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            from openpyxl import load_workbook
            
            # DataFrameìœ¼ë¡œ ë³€í™˜
            if isinstance(test_data, pd.DataFrame):
                df = test_data
            elif isinstance(test_data, list):
                df = pd.DataFrame(test_data)
            else:
                logger.error("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹")
                return False
            
            if df.empty:
                logger.warning("âš ï¸ ë¹ˆ ë°ì´í„° - ì €ì¥ ê±´ë„ˆë›°ê¸°")
                return False
            
            # ğŸ†• ì‹œí—˜ë²ˆí˜¸ ì»¬ëŸ¼ í™•ì¸
            if 'test_number' not in df.columns:
                logger.error("âŒ test_number ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # ğŸ†• ì‹œí—˜ë²ˆí˜¸ë³„ë¡œ ê·¸ë£¹í•‘
            test_numbers = df['test_number'].dropna().unique()
            
            if len(test_numbers) == 0:
                logger.warning("âš ï¸ ìœ íš¨í•œ ì‹œí—˜ë²ˆí˜¸ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            logger.info(f"ğŸ“‹ {len(test_numbers)}ê°œ ì‹œí—˜ë²ˆí˜¸ ë°œê²¬: {list(test_numbers)}")
            
            # Excel íŒŒì¼ ë¡œë“œ
            workbook = load_workbook(self.output_path)
            
            success_count = 0
            
            # ğŸ†• ê° ì‹œí—˜ë²ˆí˜¸ë³„ë¡œ ì²˜ë¦¬
            for test_number in test_numbers:
                if not test_number or str(test_number).strip() == '':
                    continue
                
                # í•´ë‹¹ ì‹œí—˜ë²ˆí˜¸ì˜ ë°ì´í„°ë§Œ ì¶”ì¶œ
                df_subset = df[df['test_number'] == test_number].copy()
                
                if df_subset.empty:
                    logger.warning(f"âš ï¸ {test_number}: ë°ì´í„° ì—†ìŒ")
                    continue
                
                logger.info(f"ğŸ”„ {test_number} ì²˜ë¦¬ ì¤‘... ({len(df_subset)}ê°œ í–‰)")
                
                # ì¤‘ë³µ ì‹œíŠ¸ëª… ì²˜ë¦¬
                sheet_name = str(test_number)
                counter = 1
                original_name = sheet_name
                while sheet_name in workbook.sheetnames:
                    sheet_name = f"{original_name}_{counter}"
                    counter += 1
                
                # ğŸ†• í…œí”Œë¦¿ ì‹œíŠ¸ ë³µì‚¬í•˜ì—¬ ìƒˆ ì‹œíŠ¸ ìƒì„±
                if "TEMPLATE_BASE" in workbook.sheetnames:
                    template_sheet = workbook["TEMPLATE_BASE"]
                    new_sheet = workbook.copy_worksheet(template_sheet)
                    new_sheet.title = sheet_name
                    logger.info(f"âœ… í…œí”Œë¦¿ ì‹œíŠ¸ ë³µì‚¬ ì™„ë£Œ: {sheet_name}")
                else:
                    # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ë¹ˆ ì‹œíŠ¸ ìƒì„±
                    new_sheet = workbook.create_sheet(title=sheet_name)
                    logger.warning(f"âš ï¸ í…œí”Œë¦¿ ì—†ì´ ë¹ˆ ì‹œíŠ¸ ìƒì„±: {sheet_name}")
                
                # ë°ì´í„° ë§¤í•‘ (í•´ë‹¹ ì‹œí—˜ë²ˆí˜¸ì˜ ë°ì´í„°ë§Œ)
                self._map_data_to_sheet(new_sheet, df_subset, date_info)
                
                success_count += 1
            
            # ì¦‰ì‹œ ì €ì¥
            workbook.save(self.output_path)
            workbook.close()
            
            logger.info(f"ğŸ’¾ Excel ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì‹œíŠ¸ ì¶”ê°€")
            return success_count > 0
            
        except Exception as e:
            logger.error(f"âŒ Excel ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _map_data_to_sheet(self, worksheet, df, date_info):
        """ë°ì´í„°ë¥¼ ì‹œíŠ¸ì— ë§¤í•‘"""
        try:
            if df.empty:
                logger.warning("âš ï¸ ë¹ˆ DataFrame - ë§¤í•‘ ê±´ë„ˆë›°ê¸°")
                return
            
            # ì‹œí—˜ë²ˆí˜¸ ë§¤í•‘
            test_number = df.iloc[0].get('test_number', '')
            worksheet['AA3'] = test_number  # ì›ë³¸ ë³´ê³ ì„œ
            worksheet['AA33'] = test_number  # Log ë³´ê³ ì„œ
            logger.info(f"ğŸ“ ì‹œí—˜ë²ˆí˜¸ ë§¤í•‘: AA3, AA33 = {test_number}")
            
            # ì²˜ë°©ë²ˆí˜¸ ë§¤í•‘
            if 'prescription_number' in df.columns:
                prescription_number = df.iloc[0].get('prescription_number', '')
                if prescription_number:
                    worksheet['E4'] = prescription_number  # ì›ë³¸
                    worksheet['E34'] = prescription_number  # Log
                    logger.info(f"ğŸ“ ì²˜ë°©ë²ˆí˜¸ ë§¤í•‘: E4, E34 = {prescription_number}")
            
            # ë‚ ì§œ ì •ë³´ ë§¤í•‘
            if date_info:
                # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                if isinstance(date_info, dict):
                    date_list = [
                        date_info.get('date_0', ''),
                        date_info.get('date_7', ''),
                        date_info.get('date_14', ''),
                        date_info.get('date_28', '')
                    ]
                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                elif isinstance(date_info, list):
                    date_list = date_info
                else:
                    date_list = []
                
                if len(date_list) >= 4:
                    date_positions_original = ['I19', 'L19', 'O19', 'R19']
                    date_positions_log = ['I49', 'L49', 'O49', 'R49']
                    
                    for i, date_val in enumerate(date_list[:4]):
                        if date_val:  # ë¹ˆ ê°’ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ë§¤í•‘
                            worksheet[date_positions_original[i]] = date_val
                            worksheet[date_positions_log[i]] = date_val
                    
                    logger.info(f"ğŸ“… ë‚ ì§œ ì •ë³´ ë§¤í•‘: {date_list}")
            
            # ê· ì£¼ë³„ CFU ë°ì´í„° ë§¤í•‘
            strain_mapping = {
                'E.coli': 'E.coli',
                'Escherichia coli': 'E.coli',
                'P.aeruginosa': 'P.aeruginosa',
                'Pseudomonas aeruginosa': 'P.aeruginosa',
                'S.aureus': 'S.aureus',
                'Staphylococcus aureus': 'S.aureus',
                'C.albicans': 'C.albicans',
                'Candida albicans': 'C.albicans',
                'A.brasiliensis': 'A.brasiliensis',
                'Aspergillus brasiliensis': 'A.brasiliensis'
            }
            
            original_positions = {
                'E.coli': ['J20', 'M20', 'P20', 'S20', 'U20'],
                'P.aeruginosa': ['J21', 'M21', 'P21', 'S21', 'U21'],
                'S.aureus': ['J22', 'M22', 'P22', 'S22', 'U22'],
                'C.albicans': ['J23', 'M23', 'P23', 'S23', 'U23'],
                'A.brasiliensis': ['J24', 'M24', 'P24', 'S24', 'U24']
            }
            
            log_positions = {
                'E.coli': ['J50', 'M50', 'P50', 'S50'],
                'P.aeruginosa': ['J51', 'M51', 'P51', 'S51'],
                'S.aureus': ['J52', 'M52', 'P52', 'S52'],
                'C.albicans': ['J53', 'M53', 'P53', 'S53'],
                'A.brasiliensis': ['J54', 'M54', 'P54', 'S54']
            }
            
            mapped_count = 0
            for _, row in df.iterrows():
                strain = row.get('strain', '')
                if not strain:
                    continue
                
                mapped_strain = strain_mapping.get(strain, strain)
                
                if mapped_strain in original_positions:
                    # ì›ë³¸ CFU ê°’
                    positions = original_positions[mapped_strain]
                    worksheet[positions[0]] = row.get('cfu_0day', '')
                    worksheet[positions[1]] = row.get('cfu_7day', '')
                    worksheet[positions[2]] = row.get('cfu_14day', '')
                    worksheet[positions[3]] = row.get('cfu_28day', '')
                    worksheet[positions[4]] = row.get('judgment', '')
                    
                    # Log ê°’
                    log_pos = log_positions[mapped_strain]
                    worksheet[log_pos[0]] = DataCleaner.convert_to_log(row.get('cfu_0day', ''))
                    worksheet[log_pos[1]] = DataCleaner.convert_to_log(row.get('cfu_7day', ''))
                    worksheet[log_pos[2]] = DataCleaner.convert_to_log(row.get('cfu_14day', ''))
                    worksheet[log_pos[3]] = DataCleaner.convert_to_log(row.get('cfu_28day', ''))
                    
                    mapped_count += 1
                    logger.info(f"ğŸ¦  {mapped_strain} ë°ì´í„° ë§¤í•‘ ì™„ë£Œ")
            
            logger.info(f"âœ… ì´ {mapped_count}ê°œ ê· ì£¼ ë°ì´í„° ë§¤í•‘ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë§¤í•‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    def get_sheet_list(self):
        """í˜„ì¬ Excel íŒŒì¼ì˜ ì‹œíŠ¸ ëª©ë¡ ë°˜í™˜"""
        try:
            from openpyxl import load_workbook
            
            if os.path.exists(self.output_path):
                workbook = load_workbook(self.output_path, read_only=True)
                sheet_names = workbook.sheetnames
                workbook.close()
                
                # TEMPLATE_BASE ì œì™¸
                filtered_names = [name for name in sheet_names if name != "TEMPLATE_BASE"]
                logger.info(f"ğŸ“‹ ì‹œíŠ¸ ëª©ë¡: {filtered_names}")
                return filtered_names
            else:
                logger.warning(f"âš ï¸ Excel íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {self.output_path}")
                return []
        except Exception as e:
            logger.error(f"âŒ ì‹œíŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_excel_bytes(self):
        """Excel íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ì–´ì„œ ë°˜í™˜ (ë‹¤ìš´ë¡œë“œìš©)"""
        try:
            if os.path.exists(self.output_path):
                with open(self.output_path, 'rb') as f:
                    excel_bytes = f.read()
                logger.info(f"âœ… Excel íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(excel_bytes)} bytes")
                return excel_bytes
            else:
                logger.warning(f"âš ï¸ Excel íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {self.output_path}")
                return None
        except Exception as e:
            logger.error(f"âŒ Excel ì½ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def get_statistics(self):
        """Excel íŒŒì¼ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            from openpyxl import load_workbook
            
            if not os.path.exists(self.output_path):
                return {
                    'total_sheets': 0,
                    'test_sheets': 0,
                    'file_size': 0
                }
            
            workbook = load_workbook(self.output_path, read_only=True)
            total_sheets = len(workbook.sheetnames)
            test_sheets = len([name for name in workbook.sheetnames if name != "TEMPLATE_BASE"])
            workbook.close()
            
            file_size = os.path.getsize(self.output_path)
            
            stats = {
                'total_sheets': total_sheets,
                'test_sheets': test_sheets,
                'file_size': file_size,
                'file_size_mb': round(file_size / (1024 * 1024), 2)
            }
            
            logger.info(f"ğŸ“Š í†µê³„: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'total_sheets': 0,
                'test_sheets': 0,
                'file_size': 0
            }

# í¸ì˜ í•¨ìˆ˜
def process_pdf_page(pdf_bytes: bytes, page_index: int, fallback_manager=None) -> dict:
    """PDF í˜ì´ì§€ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (fallback ì§€ì›)"""
    result = {
        'success': False,
        'data': [],
        'date_info': {},
        'message': ''
    }
    
    try:
                # ğŸ†• 0ë‹¨ê³„: DRM ì²˜ë¦¬
        drm_success, processed_pdf_bytes, drm_message = PDFProcessor.process_drm_if_needed(pdf_bytes)
        
        if not drm_success:
            result['message'] = drm_message
            return result
        
        logger.info(f"ğŸ“„ DRM ì²˜ë¦¬ ê²°ê³¼: {drm_message}")
        
        # ğŸ†• fallback_managerê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        if fallback_manager is None:
            fallback_manager = FallbackManager()
            
        # 1. ì´ë¯¸ì§€ ë Œë”ë§
        img_bytes = PDFProcessor.render_page_image(processed_pdf_bytes, page_index)
        if not img_bytes:
            result['message'] = "ì´ë¯¸ì§€ ë Œë”ë§ ì‹¤íŒ¨"
            return result
        
        # 2. OCR ì²˜ë¦¬
        ocr_result = OCRProcessor.request_ocr(img_bytes)
        if not ocr_result:
            result['message'] = "OCR ì²˜ë¦¬ ì‹¤íŒ¨"
            return result
        
        # 3. í…Œì´ë¸” íŒŒì‹± (ğŸ†• fallback_manager ì „ë‹¬)
        table_data, date_info = OCRProcessor.parse_table_from_ocr(ocr_result, fallback_manager)
        
        result['success'] = True
        result['data'] = table_data
        result['date_info'] = date_info
        result['message'] = f"{len(table_data)}ê°œ ê· ì£¼ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ"
        
        return result
        
    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        result['message'] = str(e)
        return result